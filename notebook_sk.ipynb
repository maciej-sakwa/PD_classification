{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import os\n",
    "from scipy.signal import detrend, butter, lfilter\n",
    "from scipy.signal.windows import tukey\n",
    "from scipy.fft import fftfreq, fft\n",
    "import joblib"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the number of files located in the data folder\n",
    "dir_path = r'./data/raw_data/single'\n",
    "source_file_nr = len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))])\n",
    "\n",
    "for number in range(source_file_nr):\n",
    "        with open(f'./data/raw_data/single/single_source_scenario_{number + 1}.data', 'rb') as pickle_file:\n",
    "                data = pickle.load(pickle_file)\n",
    "                df_sorted = data[0]\n",
    "                signals_single = data[1]\n",
    "                df_plotting_single = df_sorted[['flattened_index', 'power_dbm', 'phase_absolute']].copy()\n",
    "                df_plotting_single['cluster'] = np.full(len(signals_single), (number+1)) # Cluster labels should begin from 1\n",
    "\n",
    "        if number == 0:\n",
    "                signals = signals_single\n",
    "                df_plotting = df_plotting_single.copy()\n",
    "        else: \n",
    "                signals = np.concatenate((signals, signals_single))\n",
    "                df_plotting = pd.concat((df_plotting, df_plotting_single))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification tests"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other classifiers test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = r'./data/features/lab_single'\n",
    "source_file_nr = len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))])\n",
    "\n",
    "\n",
    "for number in range(source_file_nr):\n",
    "    \n",
    "    with open(os.path.join(dir_path, f'onset_scenario_{number + 1}'), 'rb') as file:\n",
    "        signal_extracted_scenario = pickle.load(file)\n",
    "    # create a single array with all the feature files\n",
    "    if number == 0:\n",
    "        signal_extracted = signal_extracted_scenario\n",
    "    else:\n",
    "        signal_extracted = np.append(signal_extracted, signal_extracted_scenario, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Shuffle dataset and extract variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(signal_extracted)\n",
    "\n",
    "# Unpack the data\n",
    "id_train = signal_extracted[:, 0]\n",
    "sens_train = signal_extracted[:, 1]\n",
    "cluster_train = signal_extracted[:, 2]\n",
    "signals_train = signal_extracted[:, 3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors_sorted = np.sort(np.unique(sens_train))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prepare X_train and y_train (define the binary label)\n",
    "\n",
    "    - First the Corona as PD - index 6 is corona\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.zeros(np.shape(cluster_train))\n",
    "y_train[cluster_train > 5] = 1  # the last few labels are interference (1) the first few PD (0)\n",
    "X_train = signals_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = ['accuracy', 'precision_macro', 'recall_macro', 'f1_macro'] # in the end the best model is chosen based on pure accuracy\n",
    "classifiers = {\n",
    "    'svc': SVC(),\n",
    "    'rand_forest': RandomForestClassifier(criterion='log_loss'),\n",
    "    'knn': KNeighborsClassifier(metric='minkowski'), \n",
    "    'gbc': HistGradientBoostingClassifier()}\n",
    "\n",
    "search_spaces = [\n",
    "                    {'kernel': ['poly'], 'gamma': ['scale', 'auto']},\n",
    "                    {'n_estimators': [150, 175, 200], 'criterion': ['log_loss']},\n",
    "                    {'n_neighbors': [3, 5, 10]},\n",
    "                    {'learning_rate': [0.1, 0.2, 0.3]}\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train sens: 0\n",
      "Fitting CV for: svc\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "[CV 1/5] END gamma=scale, kernel=poly; accuracy: (test=0.717) f1_macro: (test=0.632) precision_macro: (test=0.840) recall_macro: (test=0.647) total time=  10.7s\n",
      "[CV 2/5] END gamma=scale, kernel=poly; accuracy: (test=0.718) f1_macro: (test=0.634) precision_macro: (test=0.840) recall_macro: (test=0.648) total time=   9.4s\n",
      "[CV 3/5] END gamma=scale, kernel=poly; accuracy: (test=0.737) f1_macro: (test=0.665) precision_macro: (test=0.847) recall_macro: (test=0.671) total time=   9.7s\n",
      "[CV 4/5] END gamma=scale, kernel=poly; accuracy: (test=0.729) f1_macro: (test=0.652) precision_macro: (test=0.844) recall_macro: (test=0.661) total time=  10.0s\n",
      "[CV 5/5] END gamma=scale, kernel=poly; accuracy: (test=0.723) f1_macro: (test=0.641) precision_macro: (test=0.842) recall_macro: (test=0.654) total time=  10.2s\n",
      "[CV 1/5] END gamma=auto, kernel=poly; accuracy: (test=0.969) f1_macro: (test=0.968) precision_macro: (test=0.967) recall_macro: (test=0.969) total time=   2.9s\n",
      "[CV 2/5] END gamma=auto, kernel=poly; accuracy: (test=0.970) f1_macro: (test=0.969) precision_macro: (test=0.968) recall_macro: (test=0.969) total time=   2.6s\n",
      "[CV 3/5] END gamma=auto, kernel=poly; accuracy: (test=0.979) f1_macro: (test=0.978) precision_macro: (test=0.979) recall_macro: (test=0.978) total time=   3.4s\n",
      "[CV 4/5] END gamma=auto, kernel=poly; accuracy: (test=0.977) f1_macro: (test=0.976) precision_macro: (test=0.976) recall_macro: (test=0.975) total time=   2.8s\n",
      "[CV 5/5] END gamma=auto, kernel=poly; accuracy: (test=0.979) f1_macro: (test=0.978) precision_macro: (test=0.979) recall_macro: (test=0.977) total time=   2.9s\n",
      "Best score: 0.9748000879942802\n",
      "Best params: {'gamma': 'auto', 'kernel': 'poly'}\n",
      "Fitting CV for: rand_forest\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV 1/5] END criterion=log_loss, n_estimators=150; accuracy: (test=0.963) f1_macro: (test=0.962) precision_macro: (test=0.959) recall_macro: (test=0.966) total time=  11.0s\n",
      "[CV 2/5] END criterion=log_loss, n_estimators=150; accuracy: (test=0.961) f1_macro: (test=0.959) precision_macro: (test=0.956) recall_macro: (test=0.963) total time=  11.3s\n",
      "[CV 3/5] END criterion=log_loss, n_estimators=150; accuracy: (test=0.967) f1_macro: (test=0.966) precision_macro: (test=0.964) recall_macro: (test=0.968) total time=  11.6s\n",
      "[CV 4/5] END criterion=log_loss, n_estimators=150; accuracy: (test=0.973) f1_macro: (test=0.972) precision_macro: (test=0.970) recall_macro: (test=0.974) total time=  10.8s\n",
      "[CV 5/5] END criterion=log_loss, n_estimators=150; accuracy: (test=0.969) f1_macro: (test=0.968) precision_macro: (test=0.967) recall_macro: (test=0.969) total time=  11.3s\n",
      "[CV 1/5] END criterion=log_loss, n_estimators=175; accuracy: (test=0.962) f1_macro: (test=0.961) precision_macro: (test=0.958) recall_macro: (test=0.964) total time=  13.2s\n",
      "[CV 2/5] END criterion=log_loss, n_estimators=175; accuracy: (test=0.959) f1_macro: (test=0.957) precision_macro: (test=0.954) recall_macro: (test=0.961) total time=  13.1s\n",
      "[CV 3/5] END criterion=log_loss, n_estimators=175; accuracy: (test=0.969) f1_macro: (test=0.968) precision_macro: (test=0.965) recall_macro: (test=0.970) total time=  13.0s\n",
      "[CV 4/5] END criterion=log_loss, n_estimators=175; accuracy: (test=0.970) f1_macro: (test=0.969) precision_macro: (test=0.968) recall_macro: (test=0.969) total time=  13.9s\n",
      "[CV 5/5] END criterion=log_loss, n_estimators=175; accuracy: (test=0.966) f1_macro: (test=0.964) precision_macro: (test=0.963) recall_macro: (test=0.965) total time=  12.7s\n",
      "[CV 1/5] END criterion=log_loss, n_estimators=200; accuracy: (test=0.958) f1_macro: (test=0.957) precision_macro: (test=0.954) recall_macro: (test=0.960) total time=  15.3s\n",
      "[CV 2/5] END criterion=log_loss, n_estimators=200; accuracy: (test=0.960) f1_macro: (test=0.958) precision_macro: (test=0.956) recall_macro: (test=0.962) total time=  15.4s\n",
      "[CV 3/5] END criterion=log_loss, n_estimators=200; accuracy: (test=0.967) f1_macro: (test=0.966) precision_macro: (test=0.964) recall_macro: (test=0.968) total time=  15.5s\n",
      "[CV 4/5] END criterion=log_loss, n_estimators=200; accuracy: (test=0.972) f1_macro: (test=0.971) precision_macro: (test=0.969) recall_macro: (test=0.972) total time=  14.7s\n",
      "[CV 5/5] END criterion=log_loss, n_estimators=200; accuracy: (test=0.968) f1_macro: (test=0.967) precision_macro: (test=0.966) recall_macro: (test=0.967) total time=  18.0s\n",
      "Best score: 0.9665250115885324\n",
      "Best params: {'criterion': 'log_loss', 'n_estimators': 150}\n",
      "Fitting CV for: knn\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV 1/5] END n_neighbors=3; accuracy: (test=0.967) f1_macro: (test=0.966) precision_macro: (test=0.966) recall_macro: (test=0.966) total time=   0.3s\n",
      "[CV 2/5] END n_neighbors=3; accuracy: (test=0.971) f1_macro: (test=0.970) precision_macro: (test=0.970) recall_macro: (test=0.970) total time=   0.3s\n",
      "[CV 3/5] END n_neighbors=3; accuracy: (test=0.973) f1_macro: (test=0.972) precision_macro: (test=0.973) recall_macro: (test=0.970) total time=   0.3s\n",
      "[CV 4/5] END n_neighbors=3; accuracy: (test=0.975) f1_macro: (test=0.974) precision_macro: (test=0.974) recall_macro: (test=0.974) total time=   0.3s\n",
      "[CV 5/5] END n_neighbors=3; accuracy: (test=0.969) f1_macro: (test=0.968) precision_macro: (test=0.970) recall_macro: (test=0.966) total time=   0.3s\n",
      "[CV 1/5] END n_neighbors=5; accuracy: (test=0.964) f1_macro: (test=0.962) precision_macro: (test=0.962) recall_macro: (test=0.963) total time=   0.4s\n",
      "[CV 2/5] END n_neighbors=5; accuracy: (test=0.967) f1_macro: (test=0.966) precision_macro: (test=0.966) recall_macro: (test=0.966) total time=   0.4s\n",
      "[CV 3/5] END n_neighbors=5; accuracy: (test=0.974) f1_macro: (test=0.972) precision_macro: (test=0.974) recall_macro: (test=0.971) total time=   0.4s\n",
      "[CV 4/5] END n_neighbors=5; accuracy: (test=0.972) f1_macro: (test=0.971) precision_macro: (test=0.971) recall_macro: (test=0.970) total time=   0.4s\n",
      "[CV 5/5] END n_neighbors=5; accuracy: (test=0.968) f1_macro: (test=0.967) precision_macro: (test=0.968) recall_macro: (test=0.965) total time=   0.4s\n",
      "[CV 1/5] END n_neighbors=10; accuracy: (test=0.964) f1_macro: (test=0.963) precision_macro: (test=0.963) recall_macro: (test=0.963) total time=   0.4s\n",
      "[CV 2/5] END n_neighbors=10; accuracy: (test=0.956) f1_macro: (test=0.954) precision_macro: (test=0.955) recall_macro: (test=0.954) total time=   0.4s\n",
      "[CV 3/5] END n_neighbors=10; accuracy: (test=0.971) f1_macro: (test=0.969) precision_macro: (test=0.971) recall_macro: (test=0.968) total time=   0.4s\n",
      "[CV 4/5] END n_neighbors=10; accuracy: (test=0.971) f1_macro: (test=0.969) precision_macro: (test=0.971) recall_macro: (test=0.967) total time=   0.3s\n",
      "[CV 5/5] END n_neighbors=10; accuracy: (test=0.959) f1_macro: (test=0.957) precision_macro: (test=0.961) recall_macro: (test=0.953) total time=   0.3s\n",
      "Best score: 0.971163960056882\n",
      "Best params: {'n_neighbors': 3}\n",
      "Fitting CV for: gbc\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV 1/5] END learning_rate=0.1; accuracy: (test=0.971) f1_macro: (test=0.970) precision_macro: (test=0.967) recall_macro: (test=0.973) total time=  14.8s\n",
      "[CV 2/5] END learning_rate=0.1; accuracy: (test=0.960) f1_macro: (test=0.958) precision_macro: (test=0.956) recall_macro: (test=0.962) total time=  14.0s\n",
      "[CV 3/5] END learning_rate=0.1; accuracy: (test=0.971) f1_macro: (test=0.969) precision_macro: (test=0.968) recall_macro: (test=0.971) total time=  13.3s\n",
      "[CV 4/5] END learning_rate=0.1; accuracy: (test=0.969) f1_macro: (test=0.968) precision_macro: (test=0.967) recall_macro: (test=0.969) total time=  13.3s\n",
      "[CV 5/5] END learning_rate=0.1; accuracy: (test=0.971) f1_macro: (test=0.969) precision_macro: (test=0.970) recall_macro: (test=0.969) total time=  13.5s\n",
      "[CV 1/5] END learning_rate=0.2; accuracy: (test=0.967) f1_macro: (test=0.966) precision_macro: (test=0.964) recall_macro: (test=0.969) total time=  14.3s\n",
      "[CV 2/5] END learning_rate=0.2; accuracy: (test=0.964) f1_macro: (test=0.963) precision_macro: (test=0.960) recall_macro: (test=0.966) total time=  18.7s\n",
      "[CV 3/5] END learning_rate=0.2; accuracy: (test=0.975) f1_macro: (test=0.974) precision_macro: (test=0.973) recall_macro: (test=0.975) total time=  14.8s\n",
      "[CV 4/5] END learning_rate=0.2; accuracy: (test=0.971) f1_macro: (test=0.970) precision_macro: (test=0.969) recall_macro: (test=0.971) total time=  14.2s\n",
      "[CV 5/5] END learning_rate=0.2; accuracy: (test=0.969) f1_macro: (test=0.967) precision_macro: (test=0.967) recall_macro: (test=0.967) total time=  15.4s\n",
      "[CV 1/5] END learning_rate=0.3; accuracy: (test=0.967) f1_macro: (test=0.966) precision_macro: (test=0.964) recall_macro: (test=0.970) total time=  14.4s\n",
      "[CV 2/5] END learning_rate=0.3; accuracy: (test=0.962) f1_macro: (test=0.961) precision_macro: (test=0.959) recall_macro: (test=0.963) total time=  11.4s\n",
      "[CV 3/5] END learning_rate=0.3; accuracy: (test=0.975) f1_macro: (test=0.974) precision_macro: (test=0.973) recall_macro: (test=0.975) total time=  12.5s\n",
      "[CV 4/5] END learning_rate=0.3; accuracy: (test=0.970) f1_macro: (test=0.969) precision_macro: (test=0.968) recall_macro: (test=0.969) total time=  12.1s\n",
      "[CV 5/5] END learning_rate=0.3; accuracy: (test=0.971) f1_macro: (test=0.970) precision_macro: (test=0.970) recall_macro: (test=0.969) total time=  12.8s\n",
      "Best score: 0.9692830823139353\n",
      "Best params: {'learning_rate': 0.2}\n",
      "Train sens: 1\n",
      "Fitting CV for: svc\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "[CV 1/5] END gamma=scale, kernel=poly; accuracy: (test=0.786) f1_macro: (test=0.715) precision_macro: (test=0.875) recall_macro: (test=0.700) total time=   5.4s\n",
      "[CV 2/5] END gamma=scale, kernel=poly; accuracy: (test=0.774) f1_macro: (test=0.695) precision_macro: (test=0.870) recall_macro: (test=0.685) total time=   5.5s\n",
      "[CV 3/5] END gamma=scale, kernel=poly; accuracy: (test=0.780) f1_macro: (test=0.705) precision_macro: (test=0.872) recall_macro: (test=0.692) total time=   5.6s\n",
      "[CV 4/5] END gamma=scale, kernel=poly; accuracy: (test=0.786) f1_macro: (test=0.715) precision_macro: (test=0.875) recall_macro: (test=0.700) total time=   5.4s\n",
      "[CV 5/5] END gamma=scale, kernel=poly; accuracy: (test=0.793) f1_macro: (test=0.728) precision_macro: (test=0.878) recall_macro: (test=0.711) total time=   5.8s\n",
      "[CV 1/5] END gamma=auto, kernel=poly; accuracy: (test=0.987) f1_macro: (test=0.985) precision_macro: (test=0.984) recall_macro: (test=0.987) total time=   1.3s\n",
      "[CV 2/5] END gamma=auto, kernel=poly; accuracy: (test=0.984) f1_macro: (test=0.983) precision_macro: (test=0.985) recall_macro: (test=0.981) total time=   1.4s\n",
      "[CV 3/5] END gamma=auto, kernel=poly; accuracy: (test=0.987) f1_macro: (test=0.985) precision_macro: (test=0.984) recall_macro: (test=0.986) total time=   1.5s\n",
      "[CV 4/5] END gamma=auto, kernel=poly; accuracy: (test=0.988) f1_macro: (test=0.987) precision_macro: (test=0.987) recall_macro: (test=0.987) total time=   1.6s\n",
      "[CV 5/5] END gamma=auto, kernel=poly; accuracy: (test=0.991) f1_macro: (test=0.991) precision_macro: (test=0.990) recall_macro: (test=0.992) total time=   1.6s\n",
      "Best score: 0.9873688396277226\n",
      "Best params: {'gamma': 'auto', 'kernel': 'poly'}\n",
      "Fitting CV for: rand_forest\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV 1/5] END criterion=log_loss, n_estimators=150; accuracy: (test=0.984) f1_macro: (test=0.982) precision_macro: (test=0.986) recall_macro: (test=0.979) total time=   8.5s\n",
      "[CV 2/5] END criterion=log_loss, n_estimators=150; accuracy: (test=0.975) f1_macro: (test=0.973) precision_macro: (test=0.979) recall_macro: (test=0.967) total time=   8.4s\n",
      "[CV 3/5] END criterion=log_loss, n_estimators=150; accuracy: (test=0.984) f1_macro: (test=0.983) precision_macro: (test=0.988) recall_macro: (test=0.979) total time=   8.4s\n",
      "[CV 4/5] END criterion=log_loss, n_estimators=150; accuracy: (test=0.982) f1_macro: (test=0.980) precision_macro: (test=0.986) recall_macro: (test=0.975) total time=   8.4s\n",
      "[CV 5/5] END criterion=log_loss, n_estimators=150; accuracy: (test=0.987) f1_macro: (test=0.985) precision_macro: (test=0.989) recall_macro: (test=0.982) total time=   8.6s\n",
      "[CV 1/5] END criterion=log_loss, n_estimators=175; accuracy: (test=0.983) f1_macro: (test=0.981) precision_macro: (test=0.987) recall_macro: (test=0.977) total time=   9.7s\n",
      "[CV 2/5] END criterion=log_loss, n_estimators=175; accuracy: (test=0.978) f1_macro: (test=0.976) precision_macro: (test=0.983) recall_macro: (test=0.970) total time=   9.5s\n",
      "[CV 3/5] END criterion=log_loss, n_estimators=175; accuracy: (test=0.983) f1_macro: (test=0.981) precision_macro: (test=0.986) recall_macro: (test=0.977) total time=  10.1s\n",
      "[CV 4/5] END criterion=log_loss, n_estimators=175; accuracy: (test=0.982) f1_macro: (test=0.980) precision_macro: (test=0.986) recall_macro: (test=0.974) total time=  10.1s\n",
      "[CV 5/5] END criterion=log_loss, n_estimators=175; accuracy: (test=0.987) f1_macro: (test=0.985) precision_macro: (test=0.989) recall_macro: (test=0.982) total time=   9.8s\n",
      "[CV 1/5] END criterion=log_loss, n_estimators=200; accuracy: (test=0.983) f1_macro: (test=0.981) precision_macro: (test=0.987) recall_macro: (test=0.977) total time=  10.9s\n",
      "[CV 2/5] END criterion=log_loss, n_estimators=200; accuracy: (test=0.974) f1_macro: (test=0.971) precision_macro: (test=0.979) recall_macro: (test=0.964) total time=  11.0s\n",
      "[CV 3/5] END criterion=log_loss, n_estimators=200; accuracy: (test=0.984) f1_macro: (test=0.982) precision_macro: (test=0.987) recall_macro: (test=0.978) total time=  11.7s\n",
      "[CV 4/5] END criterion=log_loss, n_estimators=200; accuracy: (test=0.982) f1_macro: (test=0.980) precision_macro: (test=0.986) recall_macro: (test=0.974) total time=  11.1s\n",
      "[CV 5/5] END criterion=log_loss, n_estimators=200; accuracy: (test=0.986) f1_macro: (test=0.984) precision_macro: (test=0.988) recall_macro: (test=0.981) total time=  11.3s\n",
      "Best score: 0.982401280521873\n",
      "Best params: {'criterion': 'log_loss', 'n_estimators': 175}\n",
      "Fitting CV for: knn\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV 1/5] END n_neighbors=3; accuracy: (test=0.991) f1_macro: (test=0.991) precision_macro: (test=0.990) recall_macro: (test=0.991) total time=   0.2s\n",
      "[CV 2/5] END n_neighbors=3; accuracy: (test=0.986) f1_macro: (test=0.985) precision_macro: (test=0.985) recall_macro: (test=0.984) total time=   0.2s\n",
      "[CV 3/5] END n_neighbors=3; accuracy: (test=0.991) f1_macro: (test=0.990) precision_macro: (test=0.989) recall_macro: (test=0.991) total time=   0.2s\n",
      "[CV 4/5] END n_neighbors=3; accuracy: (test=0.991) f1_macro: (test=0.990) precision_macro: (test=0.990) recall_macro: (test=0.990) total time=   0.2s\n",
      "[CV 5/5] END n_neighbors=3; accuracy: (test=0.992) f1_macro: (test=0.992) precision_macro: (test=0.990) recall_macro: (test=0.993) total time=   0.2s\n",
      "[CV 1/5] END n_neighbors=5; accuracy: (test=0.991) f1_macro: (test=0.990) precision_macro: (test=0.990) recall_macro: (test=0.990) total time=   0.2s\n",
      "[CV 2/5] END n_neighbors=5; accuracy: (test=0.982) f1_macro: (test=0.981) precision_macro: (test=0.981) recall_macro: (test=0.980) total time=   0.2s\n",
      "[CV 3/5] END n_neighbors=5; accuracy: (test=0.989) f1_macro: (test=0.988) precision_macro: (test=0.988) recall_macro: (test=0.989) total time=   0.2s\n",
      "[CV 4/5] END n_neighbors=5; accuracy: (test=0.991) f1_macro: (test=0.990) precision_macro: (test=0.990) recall_macro: (test=0.990) total time=   0.2s\n",
      "[CV 5/5] END n_neighbors=5; accuracy: (test=0.991) f1_macro: (test=0.990) precision_macro: (test=0.989) recall_macro: (test=0.991) total time=   0.2s\n",
      "[CV 1/5] END n_neighbors=10; accuracy: (test=0.984) f1_macro: (test=0.983) precision_macro: (test=0.984) recall_macro: (test=0.982) total time=   0.3s\n",
      "[CV 2/5] END n_neighbors=10; accuracy: (test=0.979) f1_macro: (test=0.977) precision_macro: (test=0.978) recall_macro: (test=0.976) total time=   0.4s\n",
      "[CV 3/5] END n_neighbors=10; accuracy: (test=0.992) f1_macro: (test=0.991) precision_macro: (test=0.993) recall_macro: (test=0.990) total time=   0.4s\n",
      "[CV 4/5] END n_neighbors=10; accuracy: (test=0.988) f1_macro: (test=0.987) precision_macro: (test=0.988) recall_macro: (test=0.986) total time=   0.4s\n",
      "[CV 5/5] END n_neighbors=10; accuracy: (test=0.989) f1_macro: (test=0.988) precision_macro: (test=0.987) recall_macro: (test=0.989) total time=   0.4s\n",
      "Best score: 0.9902070277698082\n",
      "Best params: {'n_neighbors': 3}\n",
      "Fitting CV for: gbc\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV 1/5] END learning_rate=0.1; accuracy: (test=0.990) f1_macro: (test=0.989) precision_macro: (test=0.991) recall_macro: (test=0.988) total time=  12.4s\n",
      "[CV 2/5] END learning_rate=0.1; accuracy: (test=0.982) f1_macro: (test=0.980) precision_macro: (test=0.983) recall_macro: (test=0.976) total time=  12.1s\n",
      "[CV 3/5] END learning_rate=0.1; accuracy: (test=0.988) f1_macro: (test=0.987) precision_macro: (test=0.988) recall_macro: (test=0.985) total time=  12.7s\n",
      "[CV 4/5] END learning_rate=0.1; accuracy: (test=0.988) f1_macro: (test=0.987) precision_macro: (test=0.989) recall_macro: (test=0.984) total time=  12.2s\n",
      "[CV 5/5] END learning_rate=0.1; accuracy: (test=0.989) f1_macro: (test=0.988) precision_macro: (test=0.990) recall_macro: (test=0.987) total time=  13.0s\n",
      "[CV 1/5] END learning_rate=0.2; accuracy: (test=0.991) f1_macro: (test=0.991) precision_macro: (test=0.992) recall_macro: (test=0.990) total time=  11.5s\n",
      "[CV 2/5] END learning_rate=0.2; accuracy: (test=0.984) f1_macro: (test=0.982) precision_macro: (test=0.986) recall_macro: (test=0.979) total time=  12.2s\n",
      "[CV 3/5] END learning_rate=0.2; accuracy: (test=0.989) f1_macro: (test=0.988) precision_macro: (test=0.990) recall_macro: (test=0.985) total time=  11.6s\n",
      "[CV 4/5] END learning_rate=0.2; accuracy: (test=0.991) f1_macro: (test=0.990) precision_macro: (test=0.993) recall_macro: (test=0.987) total time=  11.8s\n",
      "[CV 5/5] END learning_rate=0.2; accuracy: (test=0.990) f1_macro: (test=0.989) precision_macro: (test=0.990) recall_macro: (test=0.988) total time=  12.1s\n",
      "[CV 1/5] END learning_rate=0.3; accuracy: (test=0.989) f1_macro: (test=0.988) precision_macro: (test=0.989) recall_macro: (test=0.986) total time=   9.0s\n",
      "[CV 2/5] END learning_rate=0.3; accuracy: (test=0.981) f1_macro: (test=0.979) precision_macro: (test=0.982) recall_macro: (test=0.976) total time=   8.9s\n",
      "[CV 3/5] END learning_rate=0.3; accuracy: (test=0.990) f1_macro: (test=0.989) precision_macro: (test=0.991) recall_macro: (test=0.987) total time=   9.0s\n",
      "[CV 4/5] END learning_rate=0.3; accuracy: (test=0.989) f1_macro: (test=0.988) precision_macro: (test=0.989) recall_macro: (test=0.987) total time=   9.1s\n",
      "[CV 5/5] END learning_rate=0.3; accuracy: (test=0.990) f1_macro: (test=0.989) precision_macro: (test=0.990) recall_macro: (test=0.989) total time=   9.1s\n",
      "Best score: 0.9889295259955\n",
      "Best params: {'learning_rate': 0.2}\n",
      "Train sens: 2\n",
      "Fitting CV for: svc\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "[CV 1/5] END gamma=scale, kernel=poly; accuracy: (test=0.759) f1_macro: (test=0.683) precision_macro: (test=0.861) recall_macro: (test=0.679) total time=  10.4s\n",
      "[CV 2/5] END gamma=scale, kernel=poly; accuracy: (test=0.754) f1_macro: (test=0.673) precision_macro: (test=0.859) recall_macro: (test=0.671) total time=  10.2s\n",
      "[CV 3/5] END gamma=scale, kernel=poly; accuracy: (test=0.738) f1_macro: (test=0.644) precision_macro: (test=0.852) recall_macro: (test=0.650) total time=  10.7s\n",
      "[CV 4/5] END gamma=scale, kernel=poly; accuracy: (test=0.745) f1_macro: (test=0.658) precision_macro: (test=0.855) recall_macro: (test=0.660) total time=  10.7s\n",
      "[CV 5/5] END gamma=scale, kernel=poly; accuracy: (test=0.743) f1_macro: (test=0.653) precision_macro: (test=0.854) recall_macro: (test=0.657) total time=  10.6s\n",
      "[CV 1/5] END gamma=auto, kernel=poly; accuracy: (test=0.942) f1_macro: (test=0.937) precision_macro: (test=0.945) recall_macro: (test=0.930) total time=   8.0s\n",
      "[CV 2/5] END gamma=auto, kernel=poly; accuracy: (test=0.945) f1_macro: (test=0.941) precision_macro: (test=0.947) recall_macro: (test=0.936) total time=   8.3s\n",
      "[CV 3/5] END gamma=auto, kernel=poly; accuracy: (test=0.937) f1_macro: (test=0.932) precision_macro: (test=0.938) recall_macro: (test=0.928) total time=   8.2s\n",
      "[CV 4/5] END gamma=auto, kernel=poly; accuracy: (test=0.935) f1_macro: (test=0.929) precision_macro: (test=0.940) recall_macro: (test=0.921) total time=   8.7s\n",
      "[CV 5/5] END gamma=auto, kernel=poly; accuracy: (test=0.934) f1_macro: (test=0.928) precision_macro: (test=0.936) recall_macro: (test=0.922) total time=   8.6s\n",
      "Best score: 0.9386045010354402\n",
      "Best params: {'gamma': 'auto', 'kernel': 'poly'}\n",
      "Fitting CV for: rand_forest\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV 1/5] END criterion=log_loss, n_estimators=150; accuracy: (test=0.966) f1_macro: (test=0.963) precision_macro: (test=0.973) recall_macro: (test=0.955) total time=  12.4s\n",
      "[CV 2/5] END criterion=log_loss, n_estimators=150; accuracy: (test=0.980) f1_macro: (test=0.979) precision_macro: (test=0.983) recall_macro: (test=0.975) total time=  11.5s\n",
      "[CV 3/5] END criterion=log_loss, n_estimators=150; accuracy: (test=0.972) f1_macro: (test=0.970) precision_macro: (test=0.978) recall_macro: (test=0.964) total time=  12.6s\n",
      "[CV 4/5] END criterion=log_loss, n_estimators=150; accuracy: (test=0.975) f1_macro: (test=0.974) precision_macro: (test=0.977) recall_macro: (test=0.970) total time=  11.3s\n",
      "[CV 5/5] END criterion=log_loss, n_estimators=150; accuracy: (test=0.969) f1_macro: (test=0.967) precision_macro: (test=0.972) recall_macro: (test=0.963) total time=  12.4s\n",
      "[CV 1/5] END criterion=log_loss, n_estimators=175; accuracy: (test=0.967) f1_macro: (test=0.964) precision_macro: (test=0.973) recall_macro: (test=0.957) total time=  13.7s\n",
      "[CV 2/5] END criterion=log_loss, n_estimators=175; accuracy: (test=0.979) f1_macro: (test=0.977) precision_macro: (test=0.981) recall_macro: (test=0.973) total time=  14.5s\n",
      "[CV 3/5] END criterion=log_loss, n_estimators=175; accuracy: (test=0.972) f1_macro: (test=0.970) precision_macro: (test=0.976) recall_macro: (test=0.965) total time=  13.8s\n",
      "[CV 4/5] END criterion=log_loss, n_estimators=175; accuracy: (test=0.974) f1_macro: (test=0.972) precision_macro: (test=0.976) recall_macro: (test=0.969) total time=  13.5s\n",
      "[CV 5/5] END criterion=log_loss, n_estimators=175; accuracy: (test=0.969) f1_macro: (test=0.967) precision_macro: (test=0.971) recall_macro: (test=0.964) total time=  14.4s\n",
      "[CV 1/5] END criterion=log_loss, n_estimators=200; accuracy: (test=0.965) f1_macro: (test=0.962) precision_macro: (test=0.971) recall_macro: (test=0.955) total time=  16.0s\n",
      "[CV 2/5] END criterion=log_loss, n_estimators=200; accuracy: (test=0.976) f1_macro: (test=0.974) precision_macro: (test=0.978) recall_macro: (test=0.971) total time=  16.0s\n",
      "[CV 3/5] END criterion=log_loss, n_estimators=200; accuracy: (test=0.973) f1_macro: (test=0.971) precision_macro: (test=0.977) recall_macro: (test=0.966) total time=  15.8s\n",
      "[CV 4/5] END criterion=log_loss, n_estimators=200; accuracy: (test=0.976) f1_macro: (test=0.974) precision_macro: (test=0.977) recall_macro: (test=0.972) total time=  16.3s\n",
      "[CV 5/5] END criterion=log_loss, n_estimators=200; accuracy: (test=0.967) f1_macro: (test=0.965) precision_macro: (test=0.970) recall_macro: (test=0.961) total time=  16.0s\n",
      "Best score: 0.9726174693025523\n",
      "Best params: {'criterion': 'log_loss', 'n_estimators': 150}\n",
      "Fitting CV for: knn\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV 1/5] END n_neighbors=3; accuracy: (test=0.984) f1_macro: (test=0.983) precision_macro: (test=0.986) recall_macro: (test=0.980) total time=   0.3s\n",
      "[CV 2/5] END n_neighbors=3; accuracy: (test=0.990) f1_macro: (test=0.990) precision_macro: (test=0.990) recall_macro: (test=0.990) total time=   0.4s\n",
      "[CV 3/5] END n_neighbors=3; accuracy: (test=0.990) f1_macro: (test=0.990) precision_macro: (test=0.990) recall_macro: (test=0.989) total time=   0.3s\n",
      "[CV 4/5] END n_neighbors=3; accuracy: (test=0.986) f1_macro: (test=0.986) precision_macro: (test=0.985) recall_macro: (test=0.986) total time=   0.3s\n",
      "[CV 5/5] END n_neighbors=3; accuracy: (test=0.985) f1_macro: (test=0.984) precision_macro: (test=0.984) recall_macro: (test=0.985) total time=   0.4s\n",
      "[CV 1/5] END n_neighbors=5; accuracy: (test=0.980) f1_macro: (test=0.979) precision_macro: (test=0.982) recall_macro: (test=0.976) total time=   0.5s\n",
      "[CV 2/5] END n_neighbors=5; accuracy: (test=0.990) f1_macro: (test=0.990) precision_macro: (test=0.990) recall_macro: (test=0.989) total time=   0.5s\n",
      "[CV 3/5] END n_neighbors=5; accuracy: (test=0.991) f1_macro: (test=0.991) precision_macro: (test=0.992) recall_macro: (test=0.990) total time=   0.5s\n",
      "[CV 4/5] END n_neighbors=5; accuracy: (test=0.982) f1_macro: (test=0.980) precision_macro: (test=0.980) recall_macro: (test=0.981) total time=   0.5s\n",
      "[CV 5/5] END n_neighbors=5; accuracy: (test=0.983) f1_macro: (test=0.982) precision_macro: (test=0.983) recall_macro: (test=0.982) total time=   0.5s\n",
      "[CV 1/5] END n_neighbors=10; accuracy: (test=0.976) f1_macro: (test=0.974) precision_macro: (test=0.978) recall_macro: (test=0.971) total time=   0.5s\n",
      "[CV 2/5] END n_neighbors=10; accuracy: (test=0.985) f1_macro: (test=0.984) precision_macro: (test=0.986) recall_macro: (test=0.983) total time=   0.4s\n",
      "[CV 3/5] END n_neighbors=10; accuracy: (test=0.986) f1_macro: (test=0.986) precision_macro: (test=0.987) recall_macro: (test=0.984) total time=   0.3s\n",
      "[CV 4/5] END n_neighbors=10; accuracy: (test=0.979) f1_macro: (test=0.978) precision_macro: (test=0.978) recall_macro: (test=0.977) total time=   0.3s\n",
      "[CV 5/5] END n_neighbors=10; accuracy: (test=0.978) f1_macro: (test=0.976) precision_macro: (test=0.978) recall_macro: (test=0.975) total time=   0.4s\n",
      "Best score: 0.9872296203787917\n",
      "Best params: {'n_neighbors': 3}\n",
      "Fitting CV for: gbc\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV 1/5] END learning_rate=0.1; accuracy: (test=0.979) f1_macro: (test=0.977) precision_macro: (test=0.981) recall_macro: (test=0.973) total time=  13.9s\n",
      "[CV 2/5] END learning_rate=0.1; accuracy: (test=0.983) f1_macro: (test=0.982) precision_macro: (test=0.983) recall_macro: (test=0.981) total time=  13.7s\n",
      "[CV 3/5] END learning_rate=0.1; accuracy: (test=0.983) f1_macro: (test=0.982) precision_macro: (test=0.984) recall_macro: (test=0.981) total time=  14.2s\n",
      "[CV 4/5] END learning_rate=0.1; accuracy: (test=0.978) f1_macro: (test=0.976) precision_macro: (test=0.976) recall_macro: (test=0.976) total time=  13.5s\n",
      "[CV 5/5] END learning_rate=0.1; accuracy: (test=0.980) f1_macro: (test=0.978) precision_macro: (test=0.979) recall_macro: (test=0.978) total time=  13.9s\n",
      "[CV 1/5] END learning_rate=0.2; accuracy: (test=0.982) f1_macro: (test=0.981) precision_macro: (test=0.984) recall_macro: (test=0.978) total time=  20.0s\n",
      "[CV 2/5] END learning_rate=0.2; accuracy: (test=0.988) f1_macro: (test=0.987) precision_macro: (test=0.988) recall_macro: (test=0.986) total time=  18.4s\n",
      "[CV 3/5] END learning_rate=0.2; accuracy: (test=0.985) f1_macro: (test=0.984) precision_macro: (test=0.985) recall_macro: (test=0.982) total time=  17.3s\n",
      "[CV 4/5] END learning_rate=0.2; accuracy: (test=0.980) f1_macro: (test=0.978) precision_macro: (test=0.978) recall_macro: (test=0.979) total time=  14.3s\n",
      "[CV 5/5] END learning_rate=0.2; accuracy: (test=0.980) f1_macro: (test=0.979) precision_macro: (test=0.980) recall_macro: (test=0.978) total time=  14.1s\n",
      "[CV 1/5] END learning_rate=0.3; accuracy: (test=0.983) f1_macro: (test=0.982) precision_macro: (test=0.985) recall_macro: (test=0.980) total time=  12.4s\n",
      "[CV 2/5] END learning_rate=0.3; accuracy: (test=0.986) f1_macro: (test=0.985) precision_macro: (test=0.986) recall_macro: (test=0.984) total time=  14.6s\n",
      "[CV 3/5] END learning_rate=0.3; accuracy: (test=0.982) f1_macro: (test=0.980) precision_macro: (test=0.983) recall_macro: (test=0.978) total time=  14.0s\n",
      "[CV 4/5] END learning_rate=0.3; accuracy: (test=0.980) f1_macro: (test=0.978) precision_macro: (test=0.979) recall_macro: (test=0.978) total time=  16.0s\n",
      "[CV 5/5] END learning_rate=0.3; accuracy: (test=0.982) f1_macro: (test=0.981) precision_macro: (test=0.981) recall_macro: (test=0.981) total time=  13.6s\n",
      "Best score: 0.9829319022689189\n",
      "Best params: {'learning_rate': 0.2}\n",
      "Train sens: 3\n",
      "Fitting CV for: svc\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "[CV 1/5] END gamma=scale, kernel=poly; accuracy: (test=0.744) f1_macro: (test=0.649) precision_macro: (test=0.856) recall_macro: (test=0.652) total time=  11.8s\n",
      "[CV 2/5] END gamma=scale, kernel=poly; accuracy: (test=0.744) f1_macro: (test=0.648) precision_macro: (test=0.856) recall_macro: (test=0.651) total time=  12.1s\n",
      "[CV 3/5] END gamma=scale, kernel=poly; accuracy: (test=0.748) f1_macro: (test=0.656) precision_macro: (test=0.858) recall_macro: (test=0.657) total time=  12.0s\n",
      "[CV 4/5] END gamma=scale, kernel=poly; accuracy: (test=0.748) f1_macro: (test=0.655) precision_macro: (test=0.858) recall_macro: (test=0.656) total time=  10.7s\n",
      "[CV 5/5] END gamma=scale, kernel=poly; accuracy: (test=0.746) f1_macro: (test=0.651) precision_macro: (test=0.857) recall_macro: (test=0.654) total time=  10.7s\n",
      "[CV 1/5] END gamma=auto, kernel=poly; accuracy: (test=0.972) f1_macro: (test=0.970) precision_macro: (test=0.969) recall_macro: (test=0.971) total time=   4.0s\n",
      "[CV 2/5] END gamma=auto, kernel=poly; accuracy: (test=0.971) f1_macro: (test=0.968) precision_macro: (test=0.969) recall_macro: (test=0.968) total time=   3.5s\n",
      "[CV 3/5] END gamma=auto, kernel=poly; accuracy: (test=0.973) f1_macro: (test=0.971) precision_macro: (test=0.969) recall_macro: (test=0.973) total time=   3.5s\n",
      "[CV 4/5] END gamma=auto, kernel=poly; accuracy: (test=0.964) f1_macro: (test=0.961) precision_macro: (test=0.960) recall_macro: (test=0.962) total time=   4.0s\n",
      "[CV 5/5] END gamma=auto, kernel=poly; accuracy: (test=0.975) f1_macro: (test=0.973) precision_macro: (test=0.972) recall_macro: (test=0.975) total time=   4.0s\n",
      "Best score: 0.9709340604528979\n",
      "Best params: {'gamma': 'auto', 'kernel': 'poly'}\n",
      "Fitting CV for: rand_forest\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV 1/5] END criterion=log_loss, n_estimators=150; accuracy: (test=0.949) f1_macro: (test=0.945) precision_macro: (test=0.950) recall_macro: (test=0.940) total time=  14.1s\n",
      "[CV 2/5] END criterion=log_loss, n_estimators=150; accuracy: (test=0.951) f1_macro: (test=0.946) precision_macro: (test=0.952) recall_macro: (test=0.942) total time=  13.9s\n",
      "[CV 3/5] END criterion=log_loss, n_estimators=150; accuracy: (test=0.959) f1_macro: (test=0.955) precision_macro: (test=0.958) recall_macro: (test=0.953) total time=  14.6s\n",
      "[CV 4/5] END criterion=log_loss, n_estimators=150; accuracy: (test=0.959) f1_macro: (test=0.956) precision_macro: (test=0.959) recall_macro: (test=0.953) total time=  14.2s\n",
      "[CV 5/5] END criterion=log_loss, n_estimators=150; accuracy: (test=0.950) f1_macro: (test=0.945) precision_macro: (test=0.951) recall_macro: (test=0.940) total time=  13.5s\n",
      "[CV 1/5] END criterion=log_loss, n_estimators=175; accuracy: (test=0.946) f1_macro: (test=0.941) precision_macro: (test=0.947) recall_macro: (test=0.936) total time=  16.4s\n",
      "[CV 2/5] END criterion=log_loss, n_estimators=175; accuracy: (test=0.953) f1_macro: (test=0.948) precision_macro: (test=0.954) recall_macro: (test=0.943) total time=  17.1s\n",
      "[CV 3/5] END criterion=log_loss, n_estimators=175; accuracy: (test=0.964) f1_macro: (test=0.961) precision_macro: (test=0.962) recall_macro: (test=0.959) total time=  16.3s\n",
      "[CV 4/5] END criterion=log_loss, n_estimators=175; accuracy: (test=0.956) f1_macro: (test=0.953) precision_macro: (test=0.956) recall_macro: (test=0.950) total time=  16.0s\n",
      "[CV 5/5] END criterion=log_loss, n_estimators=175; accuracy: (test=0.951) f1_macro: (test=0.947) precision_macro: (test=0.951) recall_macro: (test=0.943) total time=  15.9s\n",
      "[CV 1/5] END criterion=log_loss, n_estimators=200; accuracy: (test=0.952) f1_macro: (test=0.948) precision_macro: (test=0.953) recall_macro: (test=0.943) total time=  18.2s\n",
      "[CV 2/5] END criterion=log_loss, n_estimators=200; accuracy: (test=0.949) f1_macro: (test=0.944) precision_macro: (test=0.952) recall_macro: (test=0.938) total time=  17.7s\n",
      "[CV 3/5] END criterion=log_loss, n_estimators=200; accuracy: (test=0.961) f1_macro: (test=0.958) precision_macro: (test=0.960) recall_macro: (test=0.955) total time=  17.7s\n",
      "[CV 4/5] END criterion=log_loss, n_estimators=200; accuracy: (test=0.959) f1_macro: (test=0.955) precision_macro: (test=0.958) recall_macro: (test=0.953) total time=  18.0s\n",
      "[CV 5/5] END criterion=log_loss, n_estimators=200; accuracy: (test=0.950) f1_macro: (test=0.945) precision_macro: (test=0.951) recall_macro: (test=0.940) total time=  29.0s\n",
      "Best score: 0.9540835889080161\n",
      "Best params: {'criterion': 'log_loss', 'n_estimators': 200}\n",
      "Fitting CV for: knn\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV 1/5] END n_neighbors=3; accuracy: (test=0.973) f1_macro: (test=0.971) precision_macro: (test=0.969) recall_macro: (test=0.972) total time=   1.2s\n",
      "[CV 2/5] END n_neighbors=3; accuracy: (test=0.965) f1_macro: (test=0.962) precision_macro: (test=0.961) recall_macro: (test=0.964) total time=   1.1s\n",
      "[CV 3/5] END n_neighbors=3; accuracy: (test=0.975) f1_macro: (test=0.973) precision_macro: (test=0.971) recall_macro: (test=0.976) total time=   1.1s\n",
      "[CV 4/5] END n_neighbors=3; accuracy: (test=0.975) f1_macro: (test=0.973) precision_macro: (test=0.972) recall_macro: (test=0.974) total time=   1.0s\n",
      "[CV 5/5] END n_neighbors=3; accuracy: (test=0.969) f1_macro: (test=0.967) precision_macro: (test=0.964) recall_macro: (test=0.970) total time=   0.6s\n",
      "[CV 1/5] END n_neighbors=5; accuracy: (test=0.972) f1_macro: (test=0.970) precision_macro: (test=0.969) recall_macro: (test=0.972) total time=   0.5s\n",
      "[CV 2/5] END n_neighbors=5; accuracy: (test=0.966) f1_macro: (test=0.964) precision_macro: (test=0.962) recall_macro: (test=0.965) total time=   0.4s\n",
      "[CV 3/5] END n_neighbors=5; accuracy: (test=0.972) f1_macro: (test=0.970) precision_macro: (test=0.968) recall_macro: (test=0.973) total time=   0.4s\n",
      "[CV 4/5] END n_neighbors=5; accuracy: (test=0.970) f1_macro: (test=0.968) precision_macro: (test=0.967) recall_macro: (test=0.969) total time=   0.4s\n",
      "[CV 5/5] END n_neighbors=5; accuracy: (test=0.968) f1_macro: (test=0.966) precision_macro: (test=0.964) recall_macro: (test=0.968) total time=   0.5s\n",
      "[CV 1/5] END n_neighbors=10; accuracy: (test=0.963) f1_macro: (test=0.960) precision_macro: (test=0.960) recall_macro: (test=0.959) total time=   0.4s\n",
      "[CV 2/5] END n_neighbors=10; accuracy: (test=0.952) f1_macro: (test=0.948) precision_macro: (test=0.949) recall_macro: (test=0.947) total time=   0.8s\n",
      "[CV 3/5] END n_neighbors=10; accuracy: (test=0.963) f1_macro: (test=0.960) precision_macro: (test=0.960) recall_macro: (test=0.961) total time=   1.4s\n",
      "[CV 4/5] END n_neighbors=10; accuracy: (test=0.963) f1_macro: (test=0.960) precision_macro: (test=0.960) recall_macro: (test=0.959) total time=   1.4s\n",
      "[CV 5/5] END n_neighbors=10; accuracy: (test=0.959) f1_macro: (test=0.956) precision_macro: (test=0.957) recall_macro: (test=0.955) total time=   1.2s\n",
      "Best score: 0.9712740024913735\n",
      "Best params: {'n_neighbors': 3}\n",
      "Fitting CV for: gbc\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV 1/5] END learning_rate=0.1; accuracy: (test=0.965) f1_macro: (test=0.962) precision_macro: (test=0.963) recall_macro: (test=0.962) total time=  34.5s\n",
      "[CV 2/5] END learning_rate=0.1; accuracy: (test=0.964) f1_macro: (test=0.961) precision_macro: (test=0.963) recall_macro: (test=0.959) total time=  31.2s\n",
      "[CV 3/5] END learning_rate=0.1; accuracy: (test=0.968) f1_macro: (test=0.966) precision_macro: (test=0.965) recall_macro: (test=0.967) total time=  24.3s\n",
      "[CV 4/5] END learning_rate=0.1; accuracy: (test=0.963) f1_macro: (test=0.960) precision_macro: (test=0.960) recall_macro: (test=0.959) total time=  39.8s\n",
      "[CV 5/5] END learning_rate=0.1; accuracy: (test=0.967) f1_macro: (test=0.965) precision_macro: (test=0.965) recall_macro: (test=0.965) total time=  28.2s\n",
      "[CV 1/5] END learning_rate=0.2; accuracy: (test=0.969) f1_macro: (test=0.966) precision_macro: (test=0.968) recall_macro: (test=0.965) total time=  24.6s\n",
      "[CV 2/5] END learning_rate=0.2; accuracy: (test=0.966) f1_macro: (test=0.963) precision_macro: (test=0.965) recall_macro: (test=0.962) total time=  27.1s\n",
      "[CV 3/5] END learning_rate=0.2; accuracy: (test=0.971) f1_macro: (test=0.969) precision_macro: (test=0.968) recall_macro: (test=0.970) total time=  33.6s\n",
      "[CV 4/5] END learning_rate=0.2; accuracy: (test=0.967) f1_macro: (test=0.965) precision_macro: (test=0.964) recall_macro: (test=0.965) total time=  21.6s\n",
      "[CV 5/5] END learning_rate=0.2; accuracy: (test=0.975) f1_macro: (test=0.973) precision_macro: (test=0.972) recall_macro: (test=0.973) total time=  14.7s\n",
      "[CV 1/5] END learning_rate=0.3; accuracy: (test=0.968) f1_macro: (test=0.966) precision_macro: (test=0.966) recall_macro: (test=0.966) total time=  14.0s\n",
      "[CV 2/5] END learning_rate=0.3; accuracy: (test=0.968) f1_macro: (test=0.966) precision_macro: (test=0.967) recall_macro: (test=0.965) total time=  14.4s\n",
      "[CV 3/5] END learning_rate=0.3; accuracy: (test=0.972) f1_macro: (test=0.970) precision_macro: (test=0.969) recall_macro: (test=0.972) total time=  14.6s\n",
      "[CV 4/5] END learning_rate=0.3; accuracy: (test=0.969) f1_macro: (test=0.967) precision_macro: (test=0.966) recall_macro: (test=0.968) total time=  13.8s\n",
      "[CV 5/5] END learning_rate=0.3; accuracy: (test=0.972) f1_macro: (test=0.970) precision_macro: (test=0.969) recall_macro: (test=0.972) total time=  14.3s\n",
      "Best score: 0.9701429086658362\n",
      "Best params: {'learning_rate': 0.3}\n"
     ]
    }
   ],
   "source": [
    "best_models_bin = []\n",
    "results_bin = []\n",
    "\n",
    "# One model per sensor is trained\n",
    "for sensor in sensors_sorted:\n",
    "    best_models_sens = []\n",
    "    results_sens = []\n",
    "\n",
    "\n",
    "    print(f'Train sens: {sensor}')\n",
    "    X_train_sens = X_train[sens_train == sensor]\n",
    "    y_train_sens = y_train[sens_train == sensor]\n",
    "\n",
    "    # Training through cv grid search\n",
    "    for i, clf_key in enumerate(list(classifiers.keys())):\n",
    "\n",
    "        print(f'Fitting CV for: {clf_key}')\n",
    "        gs_cv = GridSearchCV(estimator = classifiers[clf_key], param_grid = search_spaces[i], scoring=scores, refit='accuracy', cv = 5, verbose=3)\n",
    "        gs_cv.fit(X_train_sens, y_train_sens)\n",
    "\n",
    "        best_models_sens.append(gs_cv.best_estimator_)\n",
    "        print(f'Best score: {gs_cv.best_score_}')\n",
    "        print(f'Best params: {gs_cv.best_params_}')\n",
    "        results_sens.append(gs_cv.best_score_)\n",
    "\n",
    "    best_models_bin.append(best_models_sens)\n",
    "    results_bin.append(results_sens)\n",
    "\n",
    "results_avg_clf = np.average(np.array(results_bin), axis = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average score over sensors for svc: 0.9679268722775852\n",
      "Average score over sensors for rand_forest: 0.9689068375802434\n",
      "Average score over sensors for knn: 0.9799686526742138\n",
      "Average score over sensors for gbc: 0.9778218548110476\n"
     ]
    }
   ],
   "source": [
    "for i, clf in enumerate(classifiers.keys()):\n",
    "    print(f'Average score over sensors for {clf}: {results_avg_clf[i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prepare X_train and y_train (define the multiclass label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_mc = cluster_train\n",
    "X_train_mc = signals_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train sens: 0\n",
      "Fitting CV for: svc\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\macie\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........................gamma=scale, kernel=poly; total time=  12.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\macie\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........................gamma=scale, kernel=poly; total time=  12.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\macie\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........................gamma=scale, kernel=poly; total time=  12.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\macie\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........................gamma=scale, kernel=poly; total time=  12.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\macie\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........................gamma=scale, kernel=poly; total time=  11.8s\n",
      "[CV] END ............................gamma=auto, kernel=poly; total time=   3.5s\n",
      "[CV] END ............................gamma=auto, kernel=poly; total time=   3.3s\n",
      "[CV] END ............................gamma=auto, kernel=poly; total time=   3.2s\n",
      "[CV] END ............................gamma=auto, kernel=poly; total time=   3.6s\n",
      "[CV] END ............................gamma=auto, kernel=poly; total time=   3.1s\n",
      "Best score: 0.9563701573683424\n",
      "Best params: {'gamma': 'auto', 'kernel': 'poly'}\n",
      "Fitting CV for: rand_forest\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV] END ...............criterion=log_loss, n_estimators=150; total time=  16.1s\n",
      "[CV] END ...............criterion=log_loss, n_estimators=150; total time=  16.2s\n",
      "[CV] END ...............criterion=log_loss, n_estimators=150; total time=  16.1s\n",
      "[CV] END ...............criterion=log_loss, n_estimators=150; total time=  16.1s\n",
      "[CV] END ...............criterion=log_loss, n_estimators=150; total time=  16.1s\n",
      "[CV] END ...............criterion=log_loss, n_estimators=175; total time=  19.2s\n",
      "[CV] END ...............criterion=log_loss, n_estimators=175; total time=  19.2s\n",
      "[CV] END ...............criterion=log_loss, n_estimators=175; total time=  18.8s\n",
      "[CV] END ...............criterion=log_loss, n_estimators=175; total time=  20.0s\n",
      "[CV] END ...............criterion=log_loss, n_estimators=175; total time=  31.9s\n",
      "[CV] END ...............criterion=log_loss, n_estimators=200; total time=  37.2s\n",
      "[CV] END ...............criterion=log_loss, n_estimators=200; total time=  29.6s\n",
      "[CV] END ...............criterion=log_loss, n_estimators=200; total time=  29.6s\n",
      "[CV] END ...............criterion=log_loss, n_estimators=200; total time=  26.3s\n",
      "[CV] END ...............criterion=log_loss, n_estimators=200; total time=  24.1s\n",
      "Best score: 0.9521065987853646\n",
      "Best params: {'criterion': 'log_loss', 'n_estimators': 175}\n",
      "Fitting CV for: knn\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV] END ......................................n_neighbors=3; total time=   0.4s\n",
      "[CV] END ......................................n_neighbors=3; total time=   0.4s\n",
      "[CV] END ......................................n_neighbors=3; total time=   0.4s\n",
      "[CV] END ......................................n_neighbors=3; total time=   0.4s\n",
      "[CV] END ......................................n_neighbors=3; total time=   0.4s\n",
      "[CV] END ......................................n_neighbors=5; total time=   0.5s\n",
      "[CV] END ......................................n_neighbors=5; total time=   0.5s\n",
      "[CV] END ......................................n_neighbors=5; total time=   0.4s\n",
      "[CV] END ......................................n_neighbors=5; total time=   0.5s\n",
      "[CV] END ......................................n_neighbors=5; total time=   0.4s\n",
      "[CV] END .....................................n_neighbors=10; total time=   0.4s\n",
      "[CV] END .....................................n_neighbors=10; total time=   0.4s\n",
      "[CV] END .....................................n_neighbors=10; total time=   0.5s\n",
      "[CV] END .....................................n_neighbors=10; total time=   0.5s\n",
      "[CV] END .....................................n_neighbors=10; total time=   0.3s\n",
      "Best score: 0.9552413164572874\n",
      "Best params: {'n_neighbors': 5}\n",
      "Fitting CV for: gbc\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV] END ..................................learning_rate=0.1; total time= 2.0min\n",
      "[CV] END ..................................learning_rate=0.1; total time= 2.2min\n",
      "[CV] END ..................................learning_rate=0.1; total time= 2.3min\n",
      "[CV] END ..................................learning_rate=0.1; total time= 2.1min\n",
      "[CV] END ..................................learning_rate=0.1; total time= 2.1min\n",
      "[CV] END ..................................learning_rate=0.2; total time= 1.1min\n",
      "[CV] END ..................................learning_rate=0.2; total time=  55.5s\n",
      "[CV] END ..................................learning_rate=0.2; total time=  55.0s\n",
      "[CV] END ..................................learning_rate=0.2; total time=  55.0s\n",
      "[CV] END ..................................learning_rate=0.2; total time=  54.7s\n",
      "[CV] END ..................................learning_rate=0.3; total time=  39.3s\n",
      "[CV] END ..................................learning_rate=0.3; total time=  39.3s\n",
      "[CV] END ..................................learning_rate=0.3; total time=  40.2s\n",
      "[CV] END ..................................learning_rate=0.3; total time=  39.9s\n",
      "[CV] END ..................................learning_rate=0.3; total time=  39.5s\n",
      "Best score: 0.9571218013686253\n",
      "Best params: {'learning_rate': 0.3}\n",
      "Train sens: 1\n",
      "Fitting CV for: svc\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\macie\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........................gamma=scale, kernel=poly; total time=  10.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\macie\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........................gamma=scale, kernel=poly; total time=  11.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\macie\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........................gamma=scale, kernel=poly; total time=  10.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\macie\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........................gamma=scale, kernel=poly; total time=  12.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\macie\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........................gamma=scale, kernel=poly; total time=  10.9s\n",
      "[CV] END ............................gamma=auto, kernel=poly; total time=   2.0s\n",
      "[CV] END ............................gamma=auto, kernel=poly; total time=   1.7s\n",
      "[CV] END ............................gamma=auto, kernel=poly; total time=   1.7s\n",
      "[CV] END ............................gamma=auto, kernel=poly; total time=   2.2s\n",
      "[CV] END ............................gamma=auto, kernel=poly; total time=   2.2s\n",
      "Best score: 0.9771509395023884\n",
      "Best params: {'gamma': 'auto', 'kernel': 'poly'}\n",
      "Fitting CV for: rand_forest\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV] END ...............criterion=log_loss, n_estimators=150; total time=  13.4s\n",
      "[CV] END ...............criterion=log_loss, n_estimators=150; total time=  13.4s\n",
      "[CV] END ...............criterion=log_loss, n_estimators=150; total time=  15.3s\n",
      "[CV] END ...............criterion=log_loss, n_estimators=150; total time=  12.9s\n",
      "[CV] END ...............criterion=log_loss, n_estimators=150; total time=  15.3s\n",
      "[CV] END ...............criterion=log_loss, n_estimators=175; total time=  15.0s\n",
      "[CV] END ...............criterion=log_loss, n_estimators=175; total time=  15.2s\n",
      "[CV] END ...............criterion=log_loss, n_estimators=175; total time=  15.7s\n",
      "[CV] END ...............criterion=log_loss, n_estimators=175; total time=  17.0s\n",
      "[CV] END ...............criterion=log_loss, n_estimators=175; total time=  15.8s\n",
      "[CV] END ...............criterion=log_loss, n_estimators=200; total time=  17.7s\n",
      "[CV] END ...............criterion=log_loss, n_estimators=200; total time=  17.1s\n",
      "[CV] END ...............criterion=log_loss, n_estimators=200; total time=  17.9s\n",
      "[CV] END ...............criterion=log_loss, n_estimators=200; total time=  17.7s\n",
      "[CV] END ...............criterion=log_loss, n_estimators=200; total time=  17.5s\n",
      "Best score: 0.9753055584917627\n",
      "Best params: {'criterion': 'log_loss', 'n_estimators': 200}\n",
      "Fitting CV for: knn\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV] END ......................................n_neighbors=3; total time=   0.3s\n",
      "[CV] END ......................................n_neighbors=3; total time=   0.3s\n",
      "[CV] END ......................................n_neighbors=3; total time=   0.3s\n",
      "[CV] END ......................................n_neighbors=3; total time=   0.3s\n",
      "[CV] END ......................................n_neighbors=3; total time=   0.3s\n",
      "[CV] END ......................................n_neighbors=5; total time=   0.4s\n",
      "[CV] END ......................................n_neighbors=5; total time=   0.4s\n",
      "[CV] END ......................................n_neighbors=5; total time=   0.3s\n",
      "[CV] END ......................................n_neighbors=5; total time=   0.3s\n",
      "[CV] END ......................................n_neighbors=5; total time=   0.2s\n",
      "[CV] END .....................................n_neighbors=10; total time=   0.2s\n",
      "[CV] END .....................................n_neighbors=10; total time=   0.2s\n",
      "[CV] END .....................................n_neighbors=10; total time=   0.2s\n",
      "[CV] END .....................................n_neighbors=10; total time=   0.2s\n",
      "[CV] END .....................................n_neighbors=10; total time=   0.3s\n",
      "Best score: 0.9828275171264768\n",
      "Best params: {'n_neighbors': 3}\n",
      "Fitting CV for: gbc\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV] END ..................................learning_rate=0.1; total time= 1.2min\n",
      "[CV] END ..................................learning_rate=0.1; total time= 1.2min\n",
      "[CV] END ..................................learning_rate=0.1; total time= 1.2min\n",
      "[CV] END ..................................learning_rate=0.1; total time= 1.2min\n",
      "[CV] END ..................................learning_rate=0.1; total time= 1.2min\n",
      "[CV] END ..................................learning_rate=0.2; total time=  41.0s\n",
      "[CV] END ..................................learning_rate=0.2; total time=  41.8s\n",
      "[CV] END ..................................learning_rate=0.2; total time=  41.5s\n",
      "[CV] END ..................................learning_rate=0.2; total time=  40.9s\n",
      "[CV] END ..................................learning_rate=0.2; total time=  41.1s\n",
      "[CV] END ..................................learning_rate=0.3; total time=  30.8s\n",
      "[CV] END ..................................learning_rate=0.3; total time=  30.3s\n",
      "[CV] END ..................................learning_rate=0.3; total time=  30.8s\n",
      "[CV] END ..................................learning_rate=0.3; total time=  29.9s\n",
      "[CV] END ..................................learning_rate=0.3; total time=  29.9s\n",
      "Best score: 0.9785691778787833\n",
      "Best params: {'learning_rate': 0.1}\n",
      "Train sens: 2\n",
      "Fitting CV for: svc\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\macie\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........................gamma=scale, kernel=poly; total time=  14.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\macie\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........................gamma=scale, kernel=poly; total time=  14.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\macie\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........................gamma=scale, kernel=poly; total time=  14.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\macie\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........................gamma=scale, kernel=poly; total time=  14.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\macie\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........................gamma=scale, kernel=poly; total time=  14.3s\n",
      "[CV] END ............................gamma=auto, kernel=poly; total time=  10.9s\n",
      "[CV] END ............................gamma=auto, kernel=poly; total time=  10.4s\n",
      "[CV] END ............................gamma=auto, kernel=poly; total time=  11.2s\n",
      "[CV] END ............................gamma=auto, kernel=poly; total time=  10.6s\n",
      "[CV] END ............................gamma=auto, kernel=poly; total time=  10.8s\n",
      "Best score: 0.8602649610936904\n",
      "Best params: {'gamma': 'auto', 'kernel': 'poly'}\n",
      "Fitting CV for: rand_forest\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV] END ...............criterion=log_loss, n_estimators=150; total time=  18.3s\n",
      "[CV] END ...............criterion=log_loss, n_estimators=150; total time=  18.5s\n",
      "[CV] END ...............criterion=log_loss, n_estimators=150; total time=  18.2s\n",
      "[CV] END ...............criterion=log_loss, n_estimators=150; total time=  18.3s\n",
      "[CV] END ...............criterion=log_loss, n_estimators=150; total time=  17.9s\n",
      "[CV] END ...............criterion=log_loss, n_estimators=175; total time=  20.7s\n",
      "[CV] END ...............criterion=log_loss, n_estimators=175; total time=  21.6s\n",
      "[CV] END ...............criterion=log_loss, n_estimators=175; total time=  20.7s\n",
      "[CV] END ...............criterion=log_loss, n_estimators=175; total time=  21.4s\n",
      "[CV] END ...............criterion=log_loss, n_estimators=175; total time=  21.1s\n",
      "[CV] END ...............criterion=log_loss, n_estimators=200; total time=  24.2s\n",
      "[CV] END ...............criterion=log_loss, n_estimators=200; total time=  24.2s\n",
      "[CV] END ...............criterion=log_loss, n_estimators=200; total time=  24.2s\n",
      "[CV] END ...............criterion=log_loss, n_estimators=200; total time=  24.2s\n",
      "[CV] END ...............criterion=log_loss, n_estimators=200; total time=  24.7s\n",
      "Best score: 0.9642677333285068\n",
      "Best params: {'criterion': 'log_loss', 'n_estimators': 150}\n",
      "Fitting CV for: knn\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV] END ......................................n_neighbors=3; total time=   0.4s\n",
      "[CV] END ......................................n_neighbors=3; total time=   0.4s\n",
      "[CV] END ......................................n_neighbors=3; total time=   0.4s\n",
      "[CV] END ......................................n_neighbors=3; total time=   0.4s\n",
      "[CV] END ......................................n_neighbors=3; total time=   0.4s\n",
      "[CV] END ......................................n_neighbors=5; total time=   0.4s\n",
      "[CV] END ......................................n_neighbors=5; total time=   0.4s\n",
      "[CV] END ......................................n_neighbors=5; total time=   0.4s\n",
      "[CV] END ......................................n_neighbors=5; total time=   0.4s\n",
      "[CV] END ......................................n_neighbors=5; total time=   0.4s\n",
      "[CV] END .....................................n_neighbors=10; total time=   0.4s\n",
      "[CV] END .....................................n_neighbors=10; total time=   0.4s\n",
      "[CV] END .....................................n_neighbors=10; total time=   0.4s\n",
      "[CV] END .....................................n_neighbors=10; total time=   0.4s\n",
      "[CV] END .....................................n_neighbors=10; total time=   0.4s\n",
      "Best score: 0.9712666458522812\n",
      "Best params: {'n_neighbors': 3}\n",
      "Fitting CV for: gbc\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV] END ..................................learning_rate=0.1; total time= 1.7min\n",
      "[CV] END ..................................learning_rate=0.1; total time= 1.6min\n",
      "[CV] END ..................................learning_rate=0.1; total time= 1.6min\n",
      "[CV] END ..................................learning_rate=0.1; total time= 1.6min\n",
      "[CV] END ..................................learning_rate=0.1; total time= 1.7min\n",
      "[CV] END ..................................learning_rate=0.2; total time=  57.5s\n",
      "[CV] END ..................................learning_rate=0.2; total time=  54.6s\n",
      "[CV] END ..................................learning_rate=0.2; total time=  55.9s\n",
      "[CV] END ..................................learning_rate=0.2; total time= 1.1min\n",
      "[CV] END ..................................learning_rate=0.2; total time=  58.5s\n",
      "[CV] END ..................................learning_rate=0.3; total time=  42.8s\n",
      "[CV] END ..................................learning_rate=0.3; total time=  53.4s\n",
      "[CV] END ..................................learning_rate=0.3; total time=  47.9s\n",
      "[CV] END ..................................learning_rate=0.3; total time=  47.3s\n",
      "[CV] END ..................................learning_rate=0.3; total time=  57.0s\n",
      "Best score: 0.9700388233537405\n",
      "Best params: {'learning_rate': 0.1}\n",
      "Train sens: 3\n",
      "Fitting CV for: svc\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\macie\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........................gamma=scale, kernel=poly; total time=  19.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\macie\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........................gamma=scale, kernel=poly; total time=  16.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\macie\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........................gamma=scale, kernel=poly; total time=  16.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\macie\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........................gamma=scale, kernel=poly; total time=  17.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\macie\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........................gamma=scale, kernel=poly; total time=  16.9s\n",
      "[CV] END ............................gamma=auto, kernel=poly; total time=   4.9s\n",
      "[CV] END ............................gamma=auto, kernel=poly; total time=   5.5s\n",
      "[CV] END ............................gamma=auto, kernel=poly; total time=   5.4s\n",
      "[CV] END ............................gamma=auto, kernel=poly; total time=   5.1s\n",
      "[CV] END ............................gamma=auto, kernel=poly; total time=   4.9s\n",
      "Best score: 0.9548743570133189\n",
      "Best params: {'gamma': 'auto', 'kernel': 'poly'}\n",
      "Fitting CV for: rand_forest\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV] END ...............criterion=log_loss, n_estimators=150; total time=  20.3s\n",
      "[CV] END ...............criterion=log_loss, n_estimators=150; total time=  22.5s\n",
      "[CV] END ...............criterion=log_loss, n_estimators=150; total time=  22.7s\n",
      "[CV] END ...............criterion=log_loss, n_estimators=150; total time=  23.1s\n",
      "[CV] END ...............criterion=log_loss, n_estimators=150; total time=  22.8s\n",
      "[CV] END ...............criterion=log_loss, n_estimators=175; total time=  27.4s\n",
      "[CV] END ...............criterion=log_loss, n_estimators=175; total time=  27.1s\n",
      "[CV] END ...............criterion=log_loss, n_estimators=175; total time=  23.8s\n",
      "[CV] END ...............criterion=log_loss, n_estimators=175; total time=  23.5s\n",
      "[CV] END ...............criterion=log_loss, n_estimators=175; total time=  24.0s\n",
      "[CV] END ...............criterion=log_loss, n_estimators=200; total time=  26.6s\n",
      "[CV] END ...............criterion=log_loss, n_estimators=200; total time=  28.6s\n",
      "[CV] END ...............criterion=log_loss, n_estimators=200; total time=  28.3s\n",
      "[CV] END ...............criterion=log_loss, n_estimators=200; total time=  26.8s\n",
      "[CV] END ...............criterion=log_loss, n_estimators=200; total time=  26.7s\n",
      "Best score: 0.943677372240369\n",
      "Best params: {'criterion': 'log_loss', 'n_estimators': 200}\n",
      "Fitting CV for: knn\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV] END ......................................n_neighbors=3; total time=   0.4s\n",
      "[CV] END ......................................n_neighbors=3; total time=   0.4s\n",
      "[CV] END ......................................n_neighbors=3; total time=   0.4s\n",
      "[CV] END ......................................n_neighbors=3; total time=   0.4s\n",
      "[CV] END ......................................n_neighbors=3; total time=   0.5s\n",
      "[CV] END ......................................n_neighbors=5; total time=   0.6s\n",
      "[CV] END ......................................n_neighbors=5; total time=   0.6s\n",
      "[CV] END ......................................n_neighbors=5; total time=   0.6s\n",
      "[CV] END ......................................n_neighbors=5; total time=   0.6s\n",
      "[CV] END ......................................n_neighbors=5; total time=   0.6s\n",
      "[CV] END .....................................n_neighbors=10; total time=   0.5s\n",
      "[CV] END .....................................n_neighbors=10; total time=   0.4s\n",
      "[CV] END .....................................n_neighbors=10; total time=   0.5s\n",
      "[CV] END .....................................n_neighbors=10; total time=   0.6s\n",
      "[CV] END .....................................n_neighbors=10; total time=   0.5s\n",
      "Best score: 0.9563443057790147\n",
      "Best params: {'n_neighbors': 3}\n",
      "Fitting CV for: gbc\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV] END ..................................learning_rate=0.1; total time= 1.9min\n",
      "[CV] END ..................................learning_rate=0.1; total time= 1.7min\n",
      "[CV] END ..................................learning_rate=0.1; total time= 1.7min\n",
      "[CV] END ..................................learning_rate=0.1; total time= 1.7min\n",
      "[CV] END ..................................learning_rate=0.1; total time= 1.7min\n",
      "[CV] END ..................................learning_rate=0.2; total time= 1.1min\n",
      "[CV] END ..................................learning_rate=0.2; total time= 1.1min\n",
      "[CV] END ..................................learning_rate=0.2; total time= 1.1min\n",
      "[CV] END ..................................learning_rate=0.2; total time= 1.1min\n",
      "[CV] END ..................................learning_rate=0.2; total time= 1.2min\n",
      "[CV] END ..................................learning_rate=0.3; total time=  49.5s\n",
      "[CV] END ..................................learning_rate=0.3; total time=  52.3s\n",
      "[CV] END ..................................learning_rate=0.3; total time=  52.2s\n",
      "[CV] END ..................................learning_rate=0.3; total time=  54.0s\n",
      "[CV] END ..................................learning_rate=0.3; total time=  48.8s\n",
      "Best score: 0.955326717807182\n",
      "Best params: {'learning_rate': 0.2}\n"
     ]
    }
   ],
   "source": [
    "best_models_mc = []\n",
    "results_mc = []\n",
    "\n",
    "for sensor in sensors_sorted:\n",
    "    best_models_sens = []\n",
    "    results_sens = []\n",
    "\n",
    "\n",
    "    print(f'Train sens: {sensor}')\n",
    "    X_train_sens = X_train_mc[sens_train == sensor]\n",
    "    y_train_sens = y_train_mc[sens_train == sensor]\n",
    "\n",
    "\n",
    "    for i, clf_key in enumerate(list(classifiers.keys())):\n",
    "        print(f'Fitting CV for: {clf_key}')\n",
    "        gs_cv = GridSearchCV(estimator = classifiers[clf_key], param_grid = search_spaces[i], scoring=scores, refit='accuracy', cv = 5, verbose=2)\n",
    "        gs_cv.fit(X_train_sens, y_train_sens)\n",
    "\n",
    "        best_models_sens.append(gs_cv.best_estimator_)\n",
    "        print(f'Best score: {gs_cv.best_score_}')\n",
    "        print(f'Best params: {gs_cv.best_params_}')\n",
    "        results_sens.append(gs_cv.best_score_)\n",
    "\n",
    "\n",
    "    best_models_mc.append(best_models_sens)\n",
    "    results_mc.append(results_sens)\n",
    "\n",
    "results_avg_clf_mc = np.average(np.array(results_mc), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average score over sensors for svc: 0.9371651037444351\n",
      "Average score over sensors for rand_forest: 0.9588393157115007\n",
      "Average score over sensors for knn: 0.9664199463037649\n",
      "Average score over sensors for gbc: 0.9652641301020828\n"
     ]
    }
   ],
   "source": [
    "# results_avg_clf_mc = np.average(np.array(results_mc, dtype=list).reshape(4, -1)[:, :-1], axis = 0)\n",
    "\n",
    "for i, clf in enumerate(classifiers.keys()):\n",
    "    print(f'Average score over sensors for {clf}: {results_avg_clf_mc[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[SVC(gamma='auto', kernel='poly'),\n",
       "  RandomForestClassifier(criterion='log_loss', n_estimators=150),\n",
       "  KNeighborsClassifier(n_neighbors=3),\n",
       "  HistGradientBoostingClassifier(learning_rate=0.2)],\n",
       " [SVC(gamma='auto', kernel='poly'),\n",
       "  RandomForestClassifier(criterion='log_loss', n_estimators=175),\n",
       "  KNeighborsClassifier(n_neighbors=3),\n",
       "  HistGradientBoostingClassifier(learning_rate=0.2)],\n",
       " [SVC(gamma='auto', kernel='poly'),\n",
       "  RandomForestClassifier(criterion='log_loss', n_estimators=150),\n",
       "  KNeighborsClassifier(n_neighbors=3),\n",
       "  HistGradientBoostingClassifier(learning_rate=0.2)],\n",
       " [SVC(gamma='auto', kernel='poly'),\n",
       "  RandomForestClassifier(criterion='log_loss', n_estimators=200),\n",
       "  KNeighborsClassifier(n_neighbors=3),\n",
       "  HistGradientBoostingClassifier(learning_rate=0.3)]]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_models_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[SVC(gamma='auto', kernel='poly'),\n",
       "  RandomForestClassifier(criterion='log_loss', n_estimators=175),\n",
       "  KNeighborsClassifier(),\n",
       "  HistGradientBoostingClassifier(learning_rate=0.3)],\n",
       " [SVC(gamma='auto', kernel='poly'),\n",
       "  RandomForestClassifier(criterion='log_loss', n_estimators=200),\n",
       "  KNeighborsClassifier(n_neighbors=3),\n",
       "  HistGradientBoostingClassifier()],\n",
       " [SVC(gamma='auto', kernel='poly'),\n",
       "  RandomForestClassifier(criterion='log_loss', n_estimators=150),\n",
       "  KNeighborsClassifier(n_neighbors=3),\n",
       "  HistGradientBoostingClassifier()],\n",
       " [SVC(gamma='auto', kernel='poly'),\n",
       "  RandomForestClassifier(criterion='log_loss', n_estimators=200),\n",
       "  KNeighborsClassifier(n_neighbors=3),\n",
       "  HistGradientBoostingClassifier(learning_rate=0.2)]]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_models_mc "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix the tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path_multi = r'./data/features/lab_multi'\n",
    "test_file_names = ['onset_scenario_3', 'onset_scenario_9', 'onset_scenario_12']\n",
    "test_cases_names = ['A', 'B', 'C']\n",
    "test_cases = {}\n",
    "pd_clusters = [[2], [3], [4, 5]]\n",
    "\n",
    "\n",
    "for i, test_f in enumerate(test_file_names):\n",
    "    \n",
    "    with open(os.path.join(dir_path_multi, test_f), 'rb') as file:\n",
    "        signal_extracted_scenario = pickle.load(file)\n",
    "        \n",
    "        # Cluster labels from clustering are unordered and do not correspond to the acual class. The proper PD-int class is assigned by study of the PRPD\n",
    "        cluster_labels_old = signal_extracted_scenario[:, 2].copy()\n",
    "        cluster_labels_new = np.ones(len(cluster_labels_old))\n",
    "        cluster_labels_new[np.isin(cluster_labels_old, pd_clusters[i])] = 0\n",
    "\n",
    "        signal_extracted_scenario[:, 2] = cluster_labels_new\n",
    "        test_cases[test_cases_names[i]] = signal_extracted_scenario\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Binary test cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for case: A, classifier svc: 0.9588014981273408\n",
      "Accuracy for case: A, classifier rand_forest: 0.8838951310861424\n",
      "Accuracy for case: A, classifier knn: 0.9803370786516854\n",
      "Accuracy for case: A, classifier gbc: 0.951310861423221\n",
      "Accuracy for case: B, classifier svc: 0.9519852262234534\n",
      "Accuracy for case: B, classifier rand_forest: 0.9556786703601108\n",
      "Accuracy for case: B, classifier knn: 0.9778393351800554\n",
      "Accuracy for case: B, classifier gbc: 0.9695290858725761\n",
      "Accuracy for case: C, classifier svc: 0.8580527752502275\n",
      "Accuracy for case: C, classifier rand_forest: 0.8252957233848953\n",
      "Accuracy for case: C, classifier knn: 0.89171974522293\n",
      "Accuracy for case: C, classifier gbc: 0.8844404003639672\n"
     ]
    }
   ],
   "source": [
    "for case in test_cases_names:\n",
    "\n",
    "    data_case = test_cases[case]\n",
    "\n",
    "    id_test = data_case[:, 0]\n",
    "    sens_test = data_case[:, 1]\n",
    "    cluster_test = data_case[:, 2]\n",
    "    signals_test = data_case[:, 3:]\n",
    "    \n",
    "\n",
    "    # Scale the input and define binary label\n",
    "    X_test = signals_test\n",
    "    y_true = cluster_test\n",
    "\n",
    "    # Create merged label by sensor (average target class for all events belonging to the same instance)\n",
    "    unique_inst_id = np.sort(np.unique(id_test))\n",
    "    y_true_merged = [int(np.average(y_true[id_test == i])) for i in unique_inst_id]\n",
    "\n",
    "    \n",
    "    # Iterate through classifiers\n",
    "    for i, clf_key in enumerate(list(classifiers.keys())):\n",
    "\n",
    "        classifiers_test = [best_models_bin[j][i] for j in range(4)] # list of 4 classifiers (1 per sensor)\n",
    "\n",
    "        id_list = []\n",
    "        y_list = []\n",
    "\n",
    "        # Iterate through sensors\n",
    "        for sens in sensors_sorted:\n",
    "\n",
    "            # Extract X and id for the tried sensor\n",
    "            X_test_sens = X_test[sens_test == sens]\n",
    "            id_test_sens = id_test[sens_test == sens]\n",
    "\n",
    "            # Predict\n",
    "            y_test_sens = classifiers_test[sens].predict(X_test_sens)\n",
    "\n",
    "            id_list.extend(id_test_sens)\n",
    "            y_list.extend(y_test_sens)\n",
    "\n",
    "\n",
    "        id_array = np.array(id_list)\n",
    "        y_array = np.array(y_list)\n",
    "        y_test_merged = [round(np.average(y_array[id_array == id])+0.01) for id in unique_inst_id]\n",
    "\n",
    "        print(f'Accuracy for case: {case}, classifier {clf_key}: {accuracy_score(y_true_merged, y_test_merged)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- MC test cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for case: A, classifier svc: 0.8848314606741573\n",
      "Accuracy for case: A, classifier rand_forest: 0.9241573033707865\n",
      "Accuracy for case: A, classifier knn: 0.947565543071161\n",
      "Accuracy for case: A, classifier gbc: 0.9044943820224719\n",
      "Accuracy for case: B, classifier svc: 0.9021237303785781\n",
      "Accuracy for case: B, classifier rand_forest: 0.9362880886426593\n",
      "Accuracy for case: B, classifier knn: 0.9122807017543859\n",
      "Accuracy for case: B, classifier gbc: 0.9141274238227147\n",
      "Accuracy for case: C, classifier svc: 0.8262056414922657\n",
      "Accuracy for case: C, classifier rand_forest: 0.8762511373976342\n",
      "Accuracy for case: C, classifier knn: 0.8835304822565969\n",
      "Accuracy for case: C, classifier gbc: 0.8589626933575978\n"
     ]
    }
   ],
   "source": [
    "for case in test_cases_names:\n",
    "\n",
    "    data_case = test_cases[case]\n",
    "\n",
    "    id_test = data_case[:, 0]\n",
    "    sens_test = data_case[:, 1]\n",
    "    cluster_test = data_case[:, 2]\n",
    "    signals_test = data_case[:, 3:]\n",
    "    \n",
    "\n",
    "    # Scale the input and define binary label\n",
    "    X_test = signals_test\n",
    "    y_true = cluster_test\n",
    "\n",
    "    # Create merged label by sensor (average target class for all events belonging to the same instance)\n",
    "    unique_inst_id = np.sort(np.unique(id_test))\n",
    "    y_true_merged = [int(np.average(y_true[id_test == i])) for i in unique_inst_id]\n",
    "\n",
    "    \n",
    "    # Iterate through classifiers\n",
    "    for i, clf_key in enumerate(list(classifiers.keys())):\n",
    "\n",
    "        classifiers_test = [best_models_mc[j][i] for j in range(4)] # list of 4 classifiers (1 per sensor)\n",
    "\n",
    "        id_list = []\n",
    "        y_list = []\n",
    "\n",
    "        # Iterate through sensors\n",
    "        for sens in sensors_sorted:\n",
    "\n",
    "            # Extract X and id for the tried sensor\n",
    "            X_test_sens = X_test[sens_test == sens]\n",
    "            id_test_sens = id_test[sens_test == sens]\n",
    "\n",
    "            # Predict\n",
    "            y_test_sens = classifiers_test[sens].predict(X_test_sens)\n",
    "\n",
    "            id_list.extend(id_test_sens)\n",
    "            y_list.extend(y_test_sens)\n",
    "\n",
    "\n",
    "\n",
    "        id_array = np.array(id_list)\n",
    "        y_array = np.array(y_list)\n",
    "        y_array_merged = [round(np.average(y_array[id_array == id])+0.01) for id in unique_inst_id]\n",
    "        y_test_merged = np.zeros(len(y_array_merged))\n",
    "        y_test_merged[np.array(y_array_merged) > 5] = 1\n",
    "\n",
    "        print(f'Accuracy for case: {case}, classifier {clf_key}: {accuracy_score(y_true_merged, y_test_merged)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(131, 627)\n",
      "(57, 627)\n",
      "(46, 627)\n",
      "(21, 627)\n",
      "(133, 627)\n",
      "(57, 627)\n",
      "(389, 627)\n",
      "(167, 627)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1001, 627)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_path = r'.\\data\\test_hueng\\input'\n",
    "inputs_all = []\n",
    "\n",
    "for file in os.listdir(folder_path):\n",
    "    with open(os.path.join(folder_path, file), 'rb') as f:\n",
    "        inputs = pickle.load(f)\n",
    "        print(np.shape(inputs))\n",
    "        inputs_all.extend(inputs)\n",
    "\n",
    "np.shape(inputs_all)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(131, 3)\n",
      "(46, 3)\n",
      "(133, 3)\n",
      "(389, 3)\n"
     ]
    }
   ],
   "source": [
    "folder_path = r'.\\data\\test_hueng\\target'\n",
    "inputs_all = []\n",
    "\n",
    "for file in os.listdir(folder_path):\n",
    "    with open(os.path.join(folder_path, file), 'rb') as f:\n",
    "        inputs = pickle.load(f)\n",
    "        print(np.shape(inputs))\n",
    "        inputs_all.append(inputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
